# SAM Installation Complete

## ‚úÖ What's Installed

1. **Segment Anything Model (SAM)** package from Meta AI
2. **ViT-B model checkpoint** (358MB) - Faster, smaller version

## üöÄ Usage

### Basic Usage
```bash
python sifter_sam.py captures/capture_1764557172.jpg
```

### How It Works

1. **Model Loading** (~5-10 seconds)
   - Loads the SAM ViT-B model into memory
   - Only happens once when script starts

2. **Segmentation** (~2-5 seconds per image)
   - SAM generates masks for all objects in the image
   - Uses grid-based approach for thorough coverage

3. **Classification** (instant)
   - Filters masks by color (pumpkin/sunflower)
   - Applies proximity filters to remove false positives

## üìä Expected Performance

- **First run**: 10-15 seconds (model loading + processing)
- **Subsequent images**: 2-5 seconds each
- **Accuracy**: Best of all methods, especially for overlapping seeds

## ‚ö° When to Use Each Method

### Use **Fast Grid** ([sifter_fast.py](sifter_fast.py)) when:
- You need quick results (0.02s per image)
- Processing many images in batch
- Accuracy is good enough (~90-95%)
- **Best for**: Batch processing, real-time counting

### Use **SAM** ([sifter_sam.py](sifter_sam.py)) when:
- You need highest accuracy (~98-99%)
- Seeds are heavily overlapping
- You're validating ground truth
- Speed is not critical
- **Best for**: Research, publication, validation

### Use **Watershed** ([sifter.py](sifter.py), [sifter_simple.py](sifter_simple.py)) when:
- You want balance of speed and accuracy
- No additional dependencies allowed
- **Best for**: General use, live camera

## üîß Model Variants

We installed **ViT-B** (recommended):
- Size: 358MB
- Speed: ~2-5s per image
- Accuracy: Excellent

Alternative **ViT-H** (optional):
- Size: 2.5GB
- Speed: ~5-10s per image
- Accuracy: Marginally better
- Download: `wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth`

## üìÅ Files

- `sifter_sam.py` - SAM-based detection script
- `sam_vit_b_01ec64.pth` - SAM model checkpoint (358MB)
- `install_sam.sh` - Installation script (already ran)

## üí° Tips

1. **First run is slow**: SAM loads model into memory (~5-10 seconds)
2. **Subsequent runs are faster**: Model stays loaded
3. **Batch processing**: Process multiple images in one script run to amortize loading time
4. **GPU acceleration**: If you have CUDA, SAM will automatically use GPU for 3-5x speedup

## üêõ Troubleshooting

### "SAM not found" error:
```bash
pip install git+https://github.com/facebookresearch/segment-anything.git
```

### "Checkpoint not found" error:
```bash
wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth
```

### Out of memory:
- SAM requires ~2-4GB RAM
- Close other applications
- Use Fast Grid method instead

## üî¨ Technical Details

SAM uses:
- Vision Transformer (ViT) backbone
- Automatic mask generation with grid prompts
- IoU prediction for quality filtering
- Stability score thresholding

Our integration:
- Color-based pre-filtering for efficiency
- Proximity-based classification
- Duplicate removal across overlapping masks
